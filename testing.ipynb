{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dcc7995-ed8e-4fd9-834b-ac5934f751d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import keras_core as keras\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b1509f4-5400-4edd-945b-cef19da0912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTorch(torch.nn.Module):\n",
    "    def __init__(self, ndim):\n",
    "        super().__init__()\n",
    "        self.w = torch.nn.Parameter(torch.ones(ndim))\n",
    "    def forward(self, x):\n",
    "        return torch.matmul(self.w, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29330227-9c2e-4394-aadd-82a0ae6ae0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearKeras(keras.layers.Layer):\n",
    "    def __init__(self, ndim):\n",
    "        super().__init__()\n",
    "        self.w = self.add_weight(shape=ndim,\n",
    "                                      initializer='ones',\n",
    "                                      trainable=True)\n",
    "    def call(self, x):\n",
    "        return keras.ops.matmul(self.w, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "570b0e8a-bd31-4eb4-b1fd-150b1e4a07d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3., device='cuda:0', grad_fn=<DotBackward0>)\n",
      "tensor(3., device='cuda:0', grad_fn=<DotBackward0>)\n"
     ]
    }
   ],
   "source": [
    "lt = LinearTorch(3).to(\"cuda\")\n",
    "lk = LinearKeras(3).to(\"cuda\")\n",
    "\n",
    "v1 = torch.ones(3).to(\"cuda\")\n",
    "\n",
    "print(lt(v1))\n",
    "print(lk(v1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86912527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['vocab_size', 'n_positions', 'n_embd', 'n_layer', 'n_head', 'n_inner', 'activation_function', 'resid_pdrop', 'embd_pdrop', 'attn_pdrop', 'layer_norm_epsilon', 'initializer_range', 'summary_type', 'summary_use_proj', 'summary_activation', 'summary_first_dropout', 'summary_proj_to_labels', 'scale_attn_weights', 'use_cache', 'scale_attn_by_inverse_layer_idx', 'reorder_and_upcast_attn', 'bos_token_id', 'eos_token_id', 'return_dict', 'output_hidden_states', 'output_attentions', 'torchscript', 'torch_dtype', 'use_bfloat16', 'tf_legacy_loss', 'pruned_heads', 'tie_word_embeddings', 'is_encoder_decoder', 'is_decoder', 'cross_attention_hidden_size', 'add_cross_attention', 'tie_encoder_decoder', 'max_length', 'min_length', 'do_sample', 'early_stopping', 'num_beams', 'num_beam_groups', 'diversity_penalty', 'temperature', 'top_k', 'top_p', 'typical_p', 'repetition_penalty', 'length_penalty', 'no_repeat_ngram_size', 'encoder_no_repeat_ngram_size', 'bad_words_ids', 'num_return_sequences', 'chunk_size_feed_forward', 'output_scores', 'return_dict_in_generate', 'forced_bos_token_id', 'forced_eos_token_id', 'remove_invalid_values', 'exponential_decay_length_penalty', 'suppress_tokens', 'begin_suppress_tokens', 'architectures', 'finetuning_task', 'id2label', 'label2id', 'tokenizer_class', 'prefix', 'pad_token_id', 'sep_token_id', 'decoder_start_token_id', 'task_specific_params', 'problem_type', '_name_or_path', 'transformers_version', 'model_type', 'n_ctx'])\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFGPT2LMHeadModel\n",
    "model_hf = TFGPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "sd_hf = model_hf.get_config().keys()\n",
    "print(sd_hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bcd45fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]]\n",
      "\n",
      "  [[ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]]\n",
      "\n",
      "  [[ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]]]\n",
      "\n",
      "\n",
      " [[[ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]]\n",
      "\n",
      "  [[ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]]\n",
      "\n",
      "  [[ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]\n",
      "   [ True  True  True  True]]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "x = np.random.randn(2, 3, 4, 5)\n",
    "yt=torch.transpose(torch.from_numpy(x), -2, -1).numpy()\n",
    "yn=np.transpose(x, axes=(0, 1, 3, 2))\n",
    "\n",
    "print(yt==yn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
